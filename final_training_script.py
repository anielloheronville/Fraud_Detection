# -*- coding: utf-8 -*-
"""final_training_script.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1isDAOlhn2-pV5uprFteC8otbhMPbvu7u
"""

# final_training_script.py
import pandas as pd
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import joblib

print(">>> INICIANDO SCRIPT FINAL DE TREINAMENTO E SALVAMENTO DE ARTEFATOS <<<")

# Função de limpeza de dados
def load_and_clean_data(file_path):
    # ... (código de limpeza idêntico ao anterior)
    df = pd.read_csv('/content/drive/MyDrive/Projetos/creditcard.csv') # Removed delimiter=';'
    # Check if 'Time' column exists before dropping NA values
    if 'Time' in df.columns:
        df.dropna(subset=['Time'], inplace=True)
    cols_to_convert = df.select_dtypes(include=['object']).columns
    for col in cols_to_convert:
        print(f"Processing column: {col}") # Added print statement
        df[col] = df[col].astype(str).str.replace('.', '', regex=False).str.replace(',', '.', regex=False).str.strip('"')
        print(f"Unique values in column {col} after stripping quotes: {df[col].unique()}") # Changed print statement
        try:
            df[col] = df[col].astype(float)
        except ValueError as e:
            print(f"Error converting column {col} to float: {e}") # Added error print
            print(f"Unique values in column {col} causing error: {df[col].unique()}") # Added unique values print
            raise # Re-raise the exception after printing info
    df['Amount'] = pd.to_numeric(df['Amount'])
    df['Class'] = df['Class'].astype(int)
    return df

# 1. Carregar dados
df = load_and_clean_data('creditcard_reduzido.csv')

# 2. Preparar Features e Salvar Min/Max para a UI
features_v = [col for col in df.columns if col.startswith('V')]
ui_features_info = {}
if 'Time' in df.columns:
    ui_features_info['Time'] = {'min': df['Time'].min(), 'max': df['Time'].max()}
ui_features_info['Amount'] = {'min': df['Amount'].min(), 'max': df['Amount'].max()}

for v_col in features_v:
    ui_features_info[v_col] = {'min': df[v_col].min(), 'max': df[v_col].max()}

joblib.dump(ui_features_info, 'ui_features_info.joblib')
print("Informações de Min/Max para UI salvas em 'ui_features_info.joblib'")

# 3. Escalar dados e dividir
scaler = StandardScaler()
# Check if 'Time' column exists before scaling
cols_to_scale = ['Amount']
if 'Time' in df.columns:
    cols_to_scale.append('Time')
df[['Amount_Scaled', 'Time_Scaled']] = scaler.fit_transform(df[cols_to_scale])
features_modelo = [col for col in df.columns if col.startswith('V') or col.endswith('_Scaled')]
X = df[features_modelo]
y = df['Class']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

# 4. Treinar o modelo XGBoost (sem otimização para ser mais rápido, mas pode ser adicionado)
print("Treinando o modelo XGBoost...")
scale_pos_weight = y_train.value_counts()[0] / y_train.value_counts()[1]
model = XGBClassifier(
    objective='binary:logistic',
    scale_pos_weight=scale_pos_weight,
    use_label_encoder=False,
    eval_metric='logloss',
    n_estimators=200,
    max_depth=5,
    learning_rate=0.1,
    random_state=42,
    n_jobs=-1
)
model.fit(X_train, y_train)
print("Treinamento Concluído!")

# 5. Salvar os artefatos
joblib.dump(model, 'model_xgboost.joblib')
joblib.dump(scaler, 'scaler.joblib')
joblib.dump(features_modelo, 'features_modelo.joblib')

print("\nArtefatos salvos com sucesso:")
print("- model_xgboost.joblib (O modelo treinado)")
print("- scaler.joblib (O normalizador de dados)")
print("- features_modelo.joblib (A lista de features que o modelo espera)")